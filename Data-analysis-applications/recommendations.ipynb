{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать **recall@k** и **precision@k**.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "### Входные данные\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - **id**-шниками просмотренных и **id**-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: **id** просмотренных товаров через , затем идёт ; после чего следуют **id** купленных товаров (если такие имеются), разделённые запятой. Например, **1,2,3,4**; или **1,2,3,4;5,6**.\n",
    "\n",
    "Гарантируется, что среди **id** купленных товаров все различные.\n",
    "\n",
    "### Важно:\n",
    "\n",
    "* Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "* Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "* Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "* Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и **k** в **recall@k / precision@k**.\n",
    "\n",
    "### Задание\n",
    "\n",
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    "    * сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "    * сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "3. Для данных алгоритмов выпишите через пробел **AverageRecall@1**, **AveragePrecision@1**, **AverageRecall@5**, **AveragePrecision@5** на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "### Дополнительные вопросы\n",
    "\n",
    "1. Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров **recall@k** меняется. Подумайте, как оценить минимальное и максимальное значение **recall@k** в зависимости от правила сортировки.\n",
    "2. Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>browsed</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9, 10, 11, 9, 11, 12, 9, 11]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[16, 17, 18, 19, 20, 21]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[24, 25, 26, 27, 24]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[34, 35, 36, 34, 37, 35, 36, 37, 38, 39, 38, 39]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[42]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[47, 48, 49]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 6...</td>\n",
       "      <td>[67, 60, 63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[71, 72, 73, 74]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[76, 77, 78]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             browsed     purchased\n",
       "0                                 [0, 1, 2, 3, 4, 5]           NaN\n",
       "1                      [9, 10, 11, 9, 11, 12, 9, 11]           NaN\n",
       "2                           [16, 17, 18, 19, 20, 21]           NaN\n",
       "3                               [24, 25, 26, 27, 24]           NaN\n",
       "4   [34, 35, 36, 34, 37, 35, 36, 37, 38, 39, 38, 39]           NaN\n",
       "5                                               [42]           NaN\n",
       "6                                       [47, 48, 49]           NaN\n",
       "7  [59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 6...  [67, 60, 63]\n",
       "8                                   [71, 72, 73, 74]           NaN\n",
       "9                                       [76, 77, 78]           NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('datasets/coursera_sessions_train.txt', sep=';', header=None)\n",
    "train_data.columns = ['browsed', 'purchased']\n",
    "\n",
    "train_data.browsed = train_data.browsed.apply(lambda x: x.split(','))\n",
    "train_data.purchased = train_data.purchased.apply(lambda x: x.split(',') if x is not np.nan else np.nan)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>browsed</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 7, 8]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[13, 14, 15]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22, 23]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[28, 29, 30, 31, 32, 33]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40, 41]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[43, 44, 43, 45, 43, 45, 43, 46]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[50, 51, 47, 52, 49, 53, 54, 55, 56, 57, 58]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[63, 68, 69, 70, 66, 61, 59, 61, 66, 68]</td>\n",
       "      <td>[66, 63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[75]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[79, 80, 81, 82, 83]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        browsed purchased\n",
       "0                                     [6, 7, 8]       NaN\n",
       "1                                  [13, 14, 15]       NaN\n",
       "2                                      [22, 23]       NaN\n",
       "3                      [28, 29, 30, 31, 32, 33]       NaN\n",
       "4                                      [40, 41]       NaN\n",
       "5              [43, 44, 43, 45, 43, 45, 43, 46]       NaN\n",
       "6  [50, 51, 47, 52, 49, 53, 54, 55, 56, 57, 58]       NaN\n",
       "7      [63, 68, 69, 70, 66, 61, 59, 61, 66, 68]  [66, 63]\n",
       "8                                          [75]       NaN\n",
       "9                          [79, 80, 81, 82, 83]       NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('datasets/coursera_sessions_test.txt', sep=';', header=None)\n",
    "test_data.columns = ['browsed', 'purchased']\n",
    "\n",
    "test_data.browsed = test_data.browsed.apply(lambda x: x.split(','))\n",
    "test_data.purchased = test_data.purchased.apply(lambda x: x.split(',') if x is not np.nan else np.nan)\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browsed_counter, purchased_counter = Counter(), Counter()\n",
    "for _index, session in train_data.iterrows():\n",
    "    browsed_counter.update(session.browsed)\n",
    "    if session.purchased is not np.nan:\n",
    "        purchased_counter.update(session.purchased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ 10 просмотренных товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 73, freq: 677\n",
      "id: 158, freq: 641\n",
      "id: 204, freq: 396\n",
      "id: 262, freq: 387\n",
      "id: 162, freq: 318\n",
      "id: 7, freq: 312\n",
      "id: 137, freq: 306\n",
      "id: 1185, freq: 284\n",
      "id: 6, freq: 283\n",
      "id: 170, freq: 280\n"
     ]
    }
   ],
   "source": [
    "for id_, freq in browsed_counter.most_common(10):\n",
    "    print(f'id: {id_}, freq: {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Топ 10 просмотренных по покупаемости товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 158, freq: 14\n",
      "id: 204, freq: 12\n",
      "id: 3324, freq: 11\n",
      "id: 73, freq: 11\n",
      "id: 5569, freq: 10\n",
      "id: 3149, freq: 10\n",
      "id: 977, freq: 10\n",
      "id: 1181, freq: 9\n",
      "id: 162, freq: 8\n",
      "id: 1852, freq: 7\n"
     ]
    }
   ],
   "source": [
    "for id_, freq in purchased_counter.most_common(10):\n",
    "    print(f'id: {id_}, freq: {freq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(row, k, counter):\n",
    "    ids = pd.unique(row.browsed)\n",
    "    positions = list(range(len(ids)))\n",
    "    freqs = [counter[id_] for id_ in ids]\n",
    "    \n",
    "    brows_data = pd.DataFrame({'id_': ids, 'pos': positions, 'freq': freqs})\n",
    "    brows_data.sort_values(['freq', 'pos'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    bought = len(set(brows_data.id_[:k]).intersection(row.purchased))\n",
    "    \n",
    "    return bought / len(row.purchased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(row, k, counter):\n",
    "    ids = pd.unique(row.browsed)\n",
    "    positions = list(range(len(ids)))\n",
    "    freqs = [counter[id_] for id_ in ids]\n",
    "    \n",
    "    brows_data = pd.DataFrame({'id_': ids, 'pos': positions, 'freq': freqs})\n",
    "    brows_data.sort_values(['freq', 'pos'], ascending=[False, True], inplace=True)\n",
    "\n",
    "    bought = len(set(brows_data.id_[:k]).intersection(row.purchased))\n",
    "    \n",
    "    return bought / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик **AverageRecall@1**, **AveragePrecision@1**, **AverageRecall@5**, **AveragePrecision@5** на обучающей выборке для алгоритма, основанного на частоте просмотров товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_1 = round(sum(train_data.apply(lambda row: recall(row, 1, browsed_counter), axis=1)) / len(train_data), 2)\n",
    "avg_recall_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_1 = round(sum(train_data.apply(lambda row: precision(row, 1, browsed_counter), axis=1)) / len(train_data), 2)\n",
    "avg_prec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_5 = round(sum(train_data.apply(lambda row: recall(row, 5, browsed_counter), axis=1)) / len(train_data), 2)\n",
    "avg_recall_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_5 = round(sum(train_data.apply(lambda row: precision(row, 5, browsed_counter), axis=1)) / len(train_data), 2)\n",
    "avg_prec_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans1.txt', 'w') as f:\n",
    "    f.write(' '.join([str(x) for x in [avg_recall_1, avg_prec_1, avg_recall_5, avg_prec_5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик **AverageRecall@1**, **AveragePrecision@1**, **AverageRecall@5**, **AveragePrecision@5** на тестовой выборке для алгоритма, основанного на частоте просмотров товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_1 = round(sum(test_data.apply(lambda row: recall(row, 1, browsed_counter), axis=1)) / len(test_data), 2)\n",
    "avg_recall_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_1 = round(sum(test_data.apply(lambda row: precision(row, 1, browsed_counter), axis=1)) / len(test_data), 2)\n",
    "avg_prec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_5 = round(sum(test_data.apply(lambda row: recall(row, 5, browsed_counter), axis=1)) / len(test_data), 2)\n",
    "avg_recall_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_5 = round(sum(test_data.apply(lambda row: precision(row, 5, browsed_counter), axis=1)) / len(test_data), 2)\n",
    "avg_prec_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans2.txt', 'w') as f:\n",
    "    f.write(' '.join([str(x) for x in [avg_recall_1, avg_prec_1, avg_recall_5, avg_prec_5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик **AverageRecall@1**, **AveragePrecision@1**, **AverageRecall@5**, **AveragePrecision@5** на обучающей выборке для алгоритма, основанного на частоте покупок товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_1 = round(sum(train_data.apply(lambda row: recall(row, 1, purchased_counter), axis=1)) / len(train_data), 2)\n",
    "avg_recall_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_1 = round(sum(train_data.apply(lambda row: precision(row, 1, purchased_counter), axis=1)) / len(train_data), 2)\n",
    "avg_prec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_5 = round(sum(train_data.apply(lambda row: recall(row, 5, purchased_counter), axis=1)) / len(train_data), 2)\n",
    "avg_recall_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_5 = round(sum(train_data.apply(lambda row: precision(row, 5, purchased_counter), axis=1)) / len(train_data), 2)\n",
    "avg_prec_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans3.txt', 'w') as f:\n",
    "    f.write(' '.join([str(x) for x in [avg_recall_1, avg_prec_1, avg_recall_5, avg_prec_5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик **AverageRecall@1**, **AveragePrecision@1**, **AverageRecall@5**, **AveragePrecision@5** на тестовой выборке для алгоритма, основанного на частоте покупок товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_1 = round(sum(test_data.apply(lambda row: recall(row, 1, purchased_counter), axis=1)) / len(test_data), 2)\n",
    "avg_recall_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_1 = round(sum(test_data.apply(lambda row: precision(row, 1, purchased_counter), axis=1)) / len(test_data), 2)\n",
    "avg_prec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_recall_5 = round(sum(test_data.apply(lambda row: recall(row, 5, purchased_counter), axis=1)) / len(test_data), 2)\n",
    "avg_recall_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prec_5 = round(sum(test_data.apply(lambda row: precision(row, 5, purchased_counter), axis=1)) / len(test_data), 2)\n",
    "avg_prec_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans4.txt', 'w') as f:\n",
    "    f.write(' '.join([str(x) for x in [avg_recall_1, avg_prec_1, avg_recall_5, avg_prec_5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
